# 混合 RAG 实现 - 技术深入解析

## 🎯 概述

本文档详细解释了 Course Pilot 的 **混合 RAG (检索增强生成)** 实现，说明我们如何结合向量搜索和关键词匹配来实现卓越的课程推荐。

---

## 🏗️ 架构

```
用户查询
    ↓
┌─────────────────────────────────────┐
│   查询处理和嵌入                     │
│   (Sentence Transformers)           │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│        混合搜索引擎                  │
│  ┌───────────────┬───────────────┐  │
│  │ 向量搜索      │ 关键词匹配     │  │
│  │  (ChromaDB)   │  (精确ID)     │  │
│  │     70%       │      30%      │  │
│  └───────────────┴───────────────┘  │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│      时间表过滤                      │
│   (检索后过滤)                       │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│      分数聚合                        │
│   最终 = V×0.7 + K×0.3              │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│      LLM 增强 (Groq)                │
│   - 个性化摘要                       │
│   - 评论审核                         │
└─────────────────────────────────────┘
    ↓
排序结果
```

---

## 🔍 组件 1: 向量搜索 (70%)

### 技术栈
- **向量数据库**: ChromaDB (持久化模式)
- **嵌入模型**: `sentence-transformers/all-MiniLM-L6-v2`
  - 维度: 384
  - 速度: CPU 上约 1000 句/秒
  - 质量: 为语义相似度优化

### 工作原理

1. **索引阶段** (仅首次运行):
   ```python
   # 为每门课程创建丰富的文档
   doc = f"课程: {course_id} | 标题: {name} | 描述: {desc} | 行业: {industry} | 技能: {skills}"
   
   # 生成嵌入
   embedding = model.encode(doc)  # → 384 维向量
   
   # 存储在 ChromaDB
   collection.add(embedding, metadata, id)
   ```

2. **查询阶段**:
   ```python
   # 用户查询: "我想学习机器学习"
   query_embedding = model.encode(query)
   
   # ChromaDB 余弦相似度搜索
   results = collection.query(
       query_embeddings=[query_embedding],
       n_results=50  # 获取前 50 个候选
   )
   
   # 结果包括距离分数 (余弦为 0-2 范围)
   # 转换为相似度: similarity = 1 - distance
   ```

### 为什么用余弦相似度?

余弦相似度测量向量之间的角度，而不是大小:
- 完美匹配: cos(θ) = 1 (距离 = 0)
- 正交: cos(θ) = 0 (距离 = 1)
- 相反: cos(θ) = -1 (距离 = 2)

**示例:**
```
查询: "机器学习和 AI"
嵌入: [0.23, -0.45, 0.67, ..., 0.12]

课程 1: "机器学习导论"
嵌入: [0.25, -0.43, 0.69, ..., 0.11]
余弦距离: 0.05 → 相似度: 0.95 ✅

课程 2: "古希腊哲学"
嵌入: [-0.12, 0.34, -0.23, ..., 0.45]
余弦距离: 1.87 → 相似度: 0.13 ❌
```

---

## 🎯 组件 2: 关键词匹配 (30%)

### 为什么需要它

向量搜索在语义匹配上很好，但在精确查询上可能失败:

**问题:**
- 查询: "15-112"
- 向量搜索可能返回: "15-213", "15-122", "15-110" (相似数字)
- 用户想要: 特定的 "15-112"!

### 解决方案: 关键词提升

```python
def keyword_score(query: str, course_id: str) -> float:
    query_clean = query.lower().replace("-", "").replace(" ", "")
    course_id_clean = course_id.lower().replace("-", "").replace(" ", "")
    
    # 精确匹配: "15112" == "15112"
    if query_clean == course_id_clean:
        return 1.0  # 完美分数
    
    # 部分匹配: "112" in "15112"
    if query_clean in course_id_clean or course_id_clean in query_clean:
        return 0.5  # 中等分数
    
    return 0.0  # 无匹配
```

### 示例

| 查询 | 课程 ID | 关键词分数 |
|-----|---------|-----------|
| "15-112" | "15-112" | 1.0 |
| "15-112" | "15-213" | 0.0 |
| "112" | "15-112" | 0.5 |
| "机器学习" | "15-112" | 0.0 |

---

## ⚖️ 组件 3: 混合评分

### 公式

```python
final_score = (vector_similarity × 0.7) + (keyword_score × 0.3)
```

### 为什么是 70/30 分配?

经过测试，我们发现:
- **70% 向量**: 捕获语义意图 (大多数查询是描述性的)
- **30% 关键词**: 确保精确匹配不被埋没

### 真实示例

#### 示例 1: 语义查询
**查询:** "我想学习人工智能"

| 课程 | 向量分数 | 关键词分数 | 最终分数 |
|-----|---------|-----------|---------|
| 15-281 AI | 0.92 | 0.0 | **0.644** |
| 15-112 入门 | 0.45 | 0.0 | **0.315** |
| 15-213 系统 | 0.23 | 0.0 | **0.161** |

**结果:** AI 课程获胜 (语义匹配) ✅

#### 示例 2: 精确课程 ID
**查询:** "15-112"

| 课程 | 向量分数 | 关键词分数 | 最终分数 |
|-----|---------|-----------|---------|
| 15-112 入门 | 0.35 | 1.0 | **0.545** |
| 15-213 系统 | 0.42 | 0.0 | **0.294** |
| 15-122 命令式 | 0.38 | 0.0 | **0.266** |

**结果:** 15-112 获胜 (关键词提升) ✅

#### 示例 3: 混合查询
**查询:** "15-112 编程基础"

| 课程 | 向量分数 | 关键词分数 | 最终分数 |
|-----|---------|-----------|---------|
| 15-112 入门 | 0.88 | 1.0 | **0.916** |
| 15-213 系统 | 0.52 | 0.0 | **0.364** |
| 15-122 命令式 | 0.61 | 0.0 | **0.427** |

**结果:** 15-112 主导 (两个信号) ✅✅

---

## 📅 组件 4: 时间表过滤

### 检索后过滤

我们在混合搜索**之后**应用时间表约束，以避免过早过滤:

```python
# 1. 从混合搜索获取前 50 个候选
candidates = hybrid_search(query, top_k=50)

# 2. 按时间表过滤
for course in candidates:
    course_days = ["M", "W", "F"]
    course_times = ["9:00 AM", "9:30 AM", "10:00 AM"]
    
    # 检查用户是否有空
    for day in course_days:
        if day not in user_schedule:
            skip_course()  # 用户这天没空
        
        for time in course_times:
            if time not in user_schedule[day]:
                skip_course()  # 时间冲突
    
    # 课程符合时间表!
    add_to_results(course)
```

### 为什么检索后?

- **效率**: 向量数据库不需要知道时间表
- **灵活性**: 易于调整过滤逻辑
- **准确性**: 我们先获得最佳语义匹配，然后过滤

---

## 🤖 组件 5: LLM 增强 (Groq)

### 为什么选择 Groq?

- **速度**: 500+ tokens/秒 (vs 本地模型 10-50)
- **质量**: Llama 3.1 70B (最先进)
- **成本**: 免费层很慷慨
- **云原生**: 容器中不需要 GPU

### 用例

#### 1. 个性化摘要
```python
prompt = f"""
用户目标: {user_goals}
用户技能: {user_skills}
课程: {course_name}
描述: {course_desc}

生成 50 字个性化推荐。
"""

response = groq.chat.completions.create(
    model="llama-3.1-70b-versatile",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.7,
    max_tokens=100
)
```

**示例输出:**
> "非常适合你的 AI 职业目标！本课程涵盖神经网络和深度学习，有实践 Python 项目。你的数学背景将帮助你在理论部分表现出色。"

#### 2. 评论审核
```python
prompt = f"""
你是内容审核员。屏蔽脏话和人身攻击。
通过所有其他评论(正面、负面、中立)。

评论: "{review_text}"

用 JSON 响应: {{"Audit Status": "Pass/Fail", "Reason": "..."}}
"""
```

---

## 📊 性能特征

### 延迟分解

| 组件 | 时间 | 注释 |
|-----|------|------|
| 查询嵌入 | 10-20ms | CPU 推理 |
| ChromaDB 搜索 | 50-100ms | 从 3000+ 课程中获取 50 个结果 |
| 关键词匹配 | 1-5ms | 简单字符串操作 |
| 时间表过滤 | 5-10ms | Python 循环 |
| Groq LLM (可选) | 200-500ms | 网络 + 推理 |
| **总计** | **300-600ms** | Web 应用可接受 |

### 可扩展性

- **课程数**: ChromaDB 轻松处理 100K+ 文档
- **并发用户**: Gunicorn 2 workers × 4 threads = 8 并发
- **内存**: 约 2GB (1GB 嵌入, 1GB ChromaDB)
- **冷启动**: 约 10-15 秒 (首次请求加载模型)

---

## 🎛️ 调优参数

### 调整权重

```python
# 更多语义匹配 (更适合模糊查询)
VECTOR_WEIGHT = 0.8
KEYWORD_WEIGHT = 0.2

# 更多精确匹配 (更适合特定课程 ID)
VECTOR_WEIGHT = 0.5
KEYWORD_WEIGHT = 0.5
```

### 调整检索大小

```python
# 获取更多候选 (更慢但更全面)
results = collection.query(query_embeddings=[emb], n_results=100)

# 获取更少候选 (更快但可能错过结果)
results = collection.query(query_embeddings=[emb], n_results=20)
```

### 调整 LLM 温度

```python
# 更有创意的摘要
temperature=0.9

# 更事实性的摘要
temperature=0.3
```

---

## 🔬 测试和验证

### 测试用例

1. **语义搜索**
   - 查询: "我想学习 web 开发"
   - 预期: HTML、CSS、JavaScript 课程

2. **精确 ID**
   - 查询: "15-445"
   - 预期: 15-445 作为首选结果

3. **混合**
   - 查询: "15-112 python 编程"
   - 预期: 15-112 高分

4. **时间表过滤**
   - 查询: "机器学习" + 周一 9AM
   - 预期: 仅周一 9AM 的 ML 课程

### 验证脚本

```bash
./test_backend.sh
```

---

## 🚀 未来改进

1. **多查询检索**: 生成多个查询变体
2. **重新排序**: 使用交叉编码器进行最终重新排序
3. **用户反馈**: 从点击中学习以改进权重
4. **缓存**: 缓存热门查询
5. **A/B 测试**: 测试不同的权重配置

---

## 📚 参考资料

- [ChromaDB 文档](https://docs.trychroma.com/)
- [Sentence Transformers](https://www.sbert.net/)
- [Groq API](https://console.groq.com/docs)
- [混合搜索论文](https://arxiv.org/abs/2104.08663)
