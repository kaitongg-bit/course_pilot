{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YFNWxjouGd0R",
        "g_s3-uVMGjcQ",
        "xR-tj5pjGp9e",
        "BqAP3awqGyiA",
        "Anp1PpCpG6iP"
      ],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b76bc0c"
      },
      "source": [
        "# Course Recommendation and Review System\n",
        "\n",
        "This notebook implements a system for recommending courses based on a user's profile (resume, skills, career goals) and for submitting and auditing course reviews.\n",
        "\n",
        "The system utilizes a locally running language model (llama-cpp-python) for tasks like summarizing course descriptions into user-friendly recommendations and auditing submitted course reviews based on predefined rules.\n",
        "\n",
        "Key features include:\n",
        "- **Course Matching:** Recommends courses by comparing user profile text with course descriptions and names using TF-IDF and cosine similarity.\n",
        "- **Career Goal Expansion:** Expands user-provided skills based on common keywords associated with their career goals.\n",
        "- **Course Summarization:** Generates concise, career-goal-oriented summaries of course descriptions using the LLM.\n",
        "- **Review Auditing:** Automatically checks submitted course reviews for inappropriate content and minimum length using the LLM.\n",
        "- **Gradio Interface:** Provides a user-friendly web interface to interact with the recommendation and review functionalities.\n",
        "\n",
        "The course data is loaded from a JSON file (`cmu_courses_merged.json`). The system uses the `smolagents` library to interface with the llama-cpp LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2221096"
      },
      "source": [
        "The core functionalities of this system are implemented in the following functions:\n",
        "\n",
        "-   **`course_match`**: This function takes a user's profile and the list of courses as input and identifies the most relevant courses based on the user's background, skills, and career goals. It uses TF-IDF and cosine similarity to calculate a matching percentage for each course.\n",
        "-   **`course_summarize`**: This function takes a course description and the user's profile (optional) and uses the language model to generate a concise, single-sentence recommendation summary for the course, often highlighting its relevance to the user's career goals.\n",
        "-   **`audit_review_llm`**: This function takes a user-submitted course review and uses the language model to audit it based on predefined rules (e.g., checking for inappropriate language and minimum length). It returns an audit status (Pass/Fail) and a reason if it fails."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set up"
      ],
      "metadata": {
        "id": "YFNWxjouGd0R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-rMBlLNWcSJ"
      },
      "outputs": [],
      "source": [
        "# Install llama-cpp-python first, as this can take a while\n",
        "!CMAKE_ARGS=\"-DGGML_CUDA=on\" pip install llama-cpp-python --quiet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7592588e"
      },
      "source": [
        "!pip install scikit-learn nltk --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Clwuy1gRY921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58960fe-9c3d-45ff-e911-ec3d3b7b7f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.8/149.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install smolagents and the requets library.\n",
        "!pip -q install smolagents[toolkit]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U smolagents\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-4t-i3LKiQxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH3j0zsnWCHZ"
      },
      "outputs": [],
      "source": [
        "import json  # For handling JSON\n",
        "\n",
        "import IPython.display  # For formatting outputs\n",
        "import smolagents  # For agents\n",
        "import llama_cpp # For calling an LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggz1KbwtWxO4",
        "outputId": "3c5caf2c-8c63-4928-a445-74297af36540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (262144) -- the full capacity of the model will not be utilized\n"
          ]
        }
      ],
      "source": [
        "# Define the model that we want to work with.\n",
        "MODEL_REPO = \"bartowski/Qwen_Qwen3-4B-Instruct-2507-GGUF\"\n",
        "MODEL_FILE = \"Qwen_Qwen3-4B-Instruct-2507-Q4_K_M.gguf\"\n",
        "\n",
        "import llama_cpp\n",
        "llm_real = llama_cpp.Llama.from_pretrained(\n",
        "    repo_id=MODEL_REPO,\n",
        "    filename=MODEL_FILE,\n",
        "    n_layers=-1,\n",
        "    n_ctx=4096,\n",
        "    n_threads=8,\n",
        "    verbose=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfVksCz5by2g"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LlamaCppModel(smolagents.Model):\n",
        "    \"\"\"\n",
        "    Thin wrapper for a llama.cpp OpenAI-compatible client.\n",
        "    Pass in an object exposing `create_chat_completion(...)` (e.g., from llama_cpp).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm, model_id: str = \"llama\", **gen_defaults):\n",
        "        super().__init__()\n",
        "        self.llm = llm\n",
        "        self.model_id = model_id\n",
        "        self.gen_defaults = {\"max_tokens\": 1024, \"temperature\": 0.2}\n",
        "        self.gen_defaults.update(gen_defaults)\n",
        "\n",
        "    # ---- helpers -------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def _content_to_str(content) -> str:\n",
        "        \"\"\"\n",
        "        smolagents.ChatMessage.content may be:\n",
        "        - str\n",
        "        - list of parts (e.g., [{\"type\":\"text\",\"text\":\"...\"}, ...])\n",
        "        - dict (rare) or other\n",
        "        Normalize to a plain string for llama.cpp's chat formatter.\n",
        "        \"\"\"\n",
        "        if content is None:\n",
        "            return \"\"\n",
        "        if isinstance(content, str):\n",
        "            return content\n",
        "\n",
        "        if isinstance(content, list):\n",
        "            parts = []\n",
        "            for p in content:\n",
        "                if isinstance(p, str):\n",
        "                    parts.append(p)\n",
        "                elif isinstance(p, dict):\n",
        "                    # common structured part: {\"type\":\"text\",\"text\":\"...\"}\n",
        "                    if p.get(\"type\") == \"text\" and \"text\" in p:\n",
        "                        parts.append(str(p[\"text\"]))\n",
        "                    elif \"text\" in p:\n",
        "                        parts.append(str(p[\"text\"]))\n",
        "                    else:\n",
        "                        parts.append(json.dumps(p, ensure_ascii=False))\n",
        "                else:\n",
        "                    parts.append(str(p))\n",
        "            return \"\\n\".join([s for s in parts if s])\n",
        "\n",
        "        if isinstance(content, dict):\n",
        "            if content.get(\"type\") == \"text\" and \"text\" in content:\n",
        "                return str(content[\"text\"])\n",
        "            if \"content\" in content and isinstance(content[\"content\"], str):\n",
        "                return content[\"content\"]\n",
        "            return json.dumps(content, ensure_ascii=False)\n",
        "\n",
        "        # fallback\n",
        "        return str(content)\n",
        "\n",
        "    @staticmethod\n",
        "    def _safe_get(obj, *keys, default=None):\n",
        "        if isinstance(obj, dict):\n",
        "            for k in keys:\n",
        "                if k in obj:\n",
        "                    return obj[k]\n",
        "            return default\n",
        "        # pydantic/attr objects (llama_cpp sometimes returns these)\n",
        "        for k in keys:\n",
        "            if hasattr(obj, k):\n",
        "                return getattr(obj, k)\n",
        "        return default\n",
        "\n",
        "    def _to_openai_messages(self, messages: list[smolagents.ChatMessage]) -> list[dict]:\n",
        "        oa = []\n",
        "        for m in messages:\n",
        "            # support both attr and dict access\n",
        "            role = getattr(m, \"role\", None) or (m.get(\"role\") if isinstance(m, dict) else None) or \"user\"\n",
        "            content = getattr(m, \"content\", None) or (m.get(\"content\") if isinstance(m, dict) else None)\n",
        "            text = self._content_to_str(content)\n",
        "\n",
        "            # optionally note images (llama.cpp chat format is text-only)\n",
        "            images = getattr(m, \"images\", None) or (m.get(\"images\") if isinstance(m, dict) else None)\n",
        "            if images:\n",
        "                text = (text + f\"\\n[Note: {len(images)} image(s) omitted]\").strip()\n",
        "\n",
        "            oa.append({\"role\": role, \"content\": text})\n",
        "        return oa\n",
        "\n",
        "    def _from_openai_message(self, msg) -> smolagents.ChatMessage:\n",
        "        role = self._safe_get(msg, \"role\", default=\"assistant\")\n",
        "        content = self._safe_get(msg, \"content\", default=\"\")\n",
        "        # map tool_calls here later if you enable function/tool calling in llama.cpp\n",
        "        return smolagents.ChatMessage(role=role, content=content)\n",
        "\n",
        "    # ---- Model.generate ------------------------------------------------------\n",
        "    def generate(\n",
        "        self,\n",
        "        messages: list[smolagents.ChatMessage],\n",
        "        stop_sequences: list[str] | None = None,\n",
        "        response_format: dict[str, str] | None = None,\n",
        "        tools_to_call_from: list[smolagents.Tool] | None = None,\n",
        "        **kwargs,\n",
        "    ) -> smolagents.ChatMessage:\n",
        "        # 1) normalize messages\n",
        "        oa_msgs = self._to_openai_messages(messages)\n",
        "\n",
        "        # 2) merge params\n",
        "        params = dict(self.gen_defaults)\n",
        "        params.update(kwargs)\n",
        "        if stop_sequences:\n",
        "            params[\"stop\"] = stop_sequences\n",
        "        if response_format:\n",
        "            # llama.cpp supports OpenAI-like JSON mode on some chat formats\n",
        "            params[\"response_format\"] = response_format\n",
        "\n",
        "        # 3) call llama.cpp\n",
        "        resp = self.llm.create_chat_completion(\n",
        "            model=self.model_id,\n",
        "            messages=oa_msgs,\n",
        "            **params,\n",
        "        )\n",
        "\n",
        "        # 4) extract first message robustly\n",
        "        choices = self._safe_get(resp, \"choices\", default=[])\n",
        "        if not choices:\n",
        "            # fallback: wrap raw text if `resp` is a plain string\n",
        "            text = self._safe_get(resp, \"content\", default=str(resp))\n",
        "            return smolagents.ChatMessage(role=\"assistant\", content=text)\n",
        "\n",
        "        first = choices[0]\n",
        "        message = self._safe_get(first, \"message\", default={})\n",
        "        return self._from_openai_message(message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_llama_real = LlamaCppModel(llm_real)\n"
      ],
      "metadata": {
        "id": "4Ohayg4N0e6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS24-nyKjJx2",
        "outputId": "00cfbae2-b2e0-4fac-ce78-38edb41d02c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_markdown(markdown_string: str):\n",
        "    \"\"\"This function prints the provided string as formatted markdown.\"\"\"\n",
        "    IPython.display.display(IPython.display.Markdown(markdown_string))"
      ],
      "metadata": {
        "id": "hA6HpXYUji8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load JSON file(course info)"
      ],
      "metadata": {
        "id": "g_s3-uVMGjcQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d5859f1a",
        "outputId": "485a6e23-db1b-4386-9cc5-8464e46ff0de"
      },
      "source": [
        "# 1. Describe user input format\n",
        "print(\"Expected User Input:\")\n",
        "print(\"- Resume (text format, including work experience, education, etc.)\")\n",
        "print(\"- Specific skills (list of skills the user possesses)\")\n",
        "print(\"- Career goals (text description of desired career path)\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Examine the course JSON file structure\n",
        "print(\"Examining cmu_courses_merged.json structure...\")\n",
        "# Assuming the file exists in the specified path and has a list of course dictionaries.\n",
        "# The exact fields will be determined after loading.\n",
        "\n",
        "# 3. Load and parse the course JSON data\n",
        "import json\n",
        "\n",
        "course_file_path = '/content/drive/MyDrive/CourseSummaries/cmu_courses_merged.json'\n",
        "\n",
        "try:\n",
        "    with open(course_file_path, 'r') as f:\n",
        "        cmu_courses = json.load(f)\n",
        "    print(\"cmu_courses_merged.json loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {course_file_path} not found.\")\n",
        "    cmu_courses = []\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from {course_file_path}.\")\n",
        "    cmu_courses = []\n",
        "\n",
        "# 4. Print a sample of the loaded course data\n",
        "if cmu_courses:\n",
        "    print(\"\\nSample of loaded course data:\")\n",
        "    for i, course in enumerate(cmu_courses[:5]): # Print first 5 courses\n",
        "        print(f\"Course {i+1}:\")\n",
        "        for key, value in course.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "        print(\"-\" * 20)\n",
        "else:\n",
        "    print(\"\\nNo course data loaded.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected User Input:\n",
            "- Resume (text format, including work experience, education, etc.)\n",
            "- Specific skills (list of skills the user possesses)\n",
            "- Career goals (text description of desired career path)\n",
            "\n",
            "\n",
            "Examining cmu_courses_merged.json structure...\n",
            "cmu_courses_merged.json loaded successfully.\n",
            "\n",
            "Sample of loaded course data:\n",
            "Course 1:\n",
            "  course_id: 93721\n",
            "  course_name: Arts Management & Intellectual Property\n",
            "  description: Spring 2026 dates: Dates are January 24 and February 7th From 10:00 -3:00pm.  Introduction to Intellectual Property for Arts Managers will introduce important concepts in trademark and copyright law. A significant portion of the class will focus on copyright, with the goal of developing an understanding of the scope of rights, exceptions, and fair use. The class will also explore Creative Commons licenses, considerations related to traditional cultural expressions, and touch on the evolving discourse on intellectual property and artificial intelligence.\n",
            "  prerequisites: None\n",
            "--------------------\n",
            "Course 2:\n",
            "  course_id: 93807\n",
            "  course_name: Museum Operations\n",
            "  description: Museums aim to preserve, present, and interpret arts, culture, science, history, and heritage for the intended benefit of the public and society, as well as to create a forum for communities. All museumsregardless of type, size, and budgetface similar operational challenges (as well their own respective set of complications), which must be managed by stakeholders dedicated to executing mission and goals.   In this course, students will gain a practical understanding of museum operations and the unique and multifaceted challenges of modern museum management. The course emphasizes museum standards and best practices, as well as identifies resources both within and adjacent to the industry. Cross-cutting topics, which build upon MAM first year coursework, include governance, financial sustainability, facilities, administration, visitor engagement and education, and collection stewardship. Additionally, case studies (via assignments and class discussion) address complexities in the museum field today, such as diversity, equity, and inclusion in museum leadership, issues in collections ethics, toxic philanthropy, and risk management. Assignments focus heavily on real-world challenges, requiring practical interpretation and implementation. .\n",
            "  prerequisites: None\n",
            "--------------------\n",
            "Course 3:\n",
            "  course_id: 93812\n",
            "  course_name: Presenting Performing Arts\n",
            "  description: Presenters are cultural entities that facilitate exchange between audiences and artists through performance opportunities and educational experiences. Festivals are key components of this industry, offering unique operational opportunities and demanding specific challenges within the field of arts management. This course will cover the fundamental aspects of the performing arts presenting and festival industry in the U.S and abroad. By the end of the course, students will understand the fundamental aspects of the presenting and festival industry, including but not limited to booking/programming a season, artist management, visa/taxes and international presenting, contracts and negotiation, cultural exchange and diplomacy, labor relations, accessibility and inclusion in programming, industry resources and other topics unique to the arts presenting ecosystem....Read More\n",
            "  prerequisites: None\n",
            "--------------------\n",
            "Course 4:\n",
            "  course_id: 93814\n",
            "  course_name: Galleries and Auction Houses\n",
            "  description: This course explores the structures and dynamics of the for-profit art economy. Topics will include an exploration of various business structures and common practices within the for-profit art world, covering both primary and secondary markets. Students will examine galleries, auction houses, dealers, consultants, and emerging digital platforms while building an understanding of how the art market functions, how art is valued, and how innovation and ethics shape business models. Through case studies, guest speakers, and experiential learning, students will gain a nuanced understanding of art market systems and develop their own creative venture proposals.\n",
            "  prerequisites: None\n",
            "--------------------\n",
            "Course 5:\n",
            "  course_id: 93821\n",
            "  course_name: Marketing and Audience Engagement\n",
            "  description: The success of arts and cultural institutions in the 21st century and beyond will depend upon creative, unconventional and coordinated long-range approaches to communicating with their stakeholders. Communication is a core activity of any arts enterprise.  External Relations frames and holds together the brand of all stakeholder communications across earned and contributed income streams (marketing = earned; development = contributed).  Today's communication professionals are crucial to their arts organizations; they maintain existing audiences, secure new audiences, create future donors, and create the brand for the institution.  They interact with all aspects of the organization, from personnel to fundraising.   This course provides readings and professional presentations to guide the understanding of successful marketing and communication, while following a project-based method to allow students to investigate hands-on the opportunities addressing the changes within the arts audience and the shifting digital landscape for marketing the arts in the United States. The focus of the course is marketing and communications within a nonprofit arts organization, while recognizing that the audience doesn't typically distinguish the difference; yet, due to budget and purpose, marketing not-for-profit arts organizations is significantly different as compared to a for-profit entertainment venture. This course will provide each student with marketing principles and theories as well as opportunities to actualize theories with assignments and a final project utilizing current technologies.   The course requires active, practical engagement and intellectual rigor.\n",
            "  prerequisites: None\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define course_match function"
      ],
      "metadata": {
        "id": "xR-tj5pjGp9e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95481cd4"
      },
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    tokens = text.split()   # Replace nltk.word_tokenize(text) with split\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "def course_match(user_profile: dict, courses: list) -> list:\n",
        "    \"\"\"\n",
        "    Matches user profile (resume, skills, career goals) with courses.\n",
        "\n",
        "    Args:\n",
        "        user_profile: A dictionary containing 'resume' (str), 'skills' (list of str), 'career_goals' (str).\n",
        "        courses: A list of course dictionaries, each with 'course_name', 'description', 'prerequisites', etc.\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries, each containing course details and a 'matching_percentage',\n",
        "        sorted by 'matching_percentage' in descending order.\n",
        "    \"\"\"\n",
        "    user_text = preprocess_text(user_profile.get('resume', '') + \" \".join(user_profile.get('skills', [])) + user_profile.get('career_goals', ''))\n",
        "\n",
        "    if not user_text:\n",
        "        print(\"Warning: User profile text is empty. Cannot perform matching.\")\n",
        "        return []\n",
        "\n",
        "    course_texts = [preprocess_text(course.get('course_name', '') + \" \" + course.get('description', '') + \" \" + course.get('prerequisites', '')) for course in courses]\n",
        "\n",
        "    if not course_texts:\n",
        "        print(\"Warning: No course texts available for matching.\")\n",
        "        return []\n",
        "\n",
        "    # Use TF-IDF and Cosine Similarity for matching\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform([user_text] + course_texts)\n",
        "\n",
        "    # Calculate cosine similarity between user profile and each course\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
        "\n",
        "    matched_courses = []\n",
        "    for i, course in enumerate(courses):\n",
        "        matching_percentage = cosine_sim[i] * 100  # Convert similarity to percentage\n",
        "        matched_courses.append({\n",
        "            'course_id': course.get('course_id'),\n",
        "            'course_name': course.get('course_name'),\n",
        "            'description': course.get('description'), # Keep full description for summarize tool later\n",
        "            'prerequisites': course.get('prerequisites'),\n",
        "            'matching_percentage': round(matching_percentage, 2)\n",
        "        })\n",
        "\n",
        "    # Sort by matching percentage\n",
        "    matched_courses = sorted(matched_courses, key=lambda x: x['matching_percentage'], reverse=True)\n",
        "\n",
        "    return matched_courses\n",
        "\n",
        "# Example Usage (for testing the function)\n",
        "# Make sure cmu_courses is loaded from the previous step\n",
        "# user_example = {\n",
        "#     'resume': 'Experienced in Python programming and machine learning projects.',\n",
        "#     'skills': ['Python', 'Machine Learning', 'NLP'],\n",
        "#     'career_goals': 'Become an AI Product Manager'\n",
        "# }\n",
        "#\n",
        "# if 'cmu_courses' in locals() and cmu_courses:\n",
        "#      matched_courses_example = course_match(user_example, cmu_courses)\n",
        "#      print(\"\\nExample Matching Results:\")\n",
        "#      for course in matched_courses_example[:10]: # Print top 10 matches\n",
        "#          print(f\"Course: {course['course_name']} (Match: {course['matching_percentage']}%)\")\n",
        "# else:\n",
        "#     print(\"\\nCourse data not loaded. Cannot run example matching.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Place before all model/flow code\n",
        "job_keywords_map = {\n",
        "    \"AI product manager\": [\n",
        "        \"product management\", \"python\", \"machine learning\", \"deep learning\",\n",
        "        \"data analysis\", \"artificial intelligence\", \"user experience\", \"business analysis\",\n",
        "        \"prompt engineering\", \"algorithms\", \"app development\"\n",
        "    ],\n",
        "    \"data scientist\": [\n",
        "        \"python\", \"machine learning\", \"statistics\", \"data mining\", \"data visualization\",\n",
        "        \"deep learning\", \"SQL\", \"big data\"\n",
        "    ],\n",
        "    # Add more professions as needed\n",
        "}"
      ],
      "metadata": {
        "id": "STtJ1W895m87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_job(s):\n",
        "    return re.sub(r'[^a-z0-9 ]', '', s.lower()).strip()\n",
        "\n",
        "def expand_profile(user_profile):\n",
        "    goal = normalize_job(user_profile.get('career_goals', ''))\n",
        "    extra_skills = set()\n",
        "    for k, kws in job_keywords_map.items():\n",
        "        k_norm = normalize_job(k)\n",
        "        # Trigger if the goal description contains the keyword key, or if all words after tokenization are in the goal\n",
        "        if k_norm in goal or all(word in goal for word in k_norm.split()):\n",
        "            extra_skills.update(kws)\n",
        "    skills = set([s.lower() for s in user_profile.get('skills', [])])\n",
        "    total_skills = list(skills | extra_skills)\n",
        "    new_profile = dict(user_profile)\n",
        "    new_profile['skills'] = total_skills\n",
        "    return new_profile"
      ],
      "metadata": {
        "id": "T5T3YkD75rql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define course_summarize(recommendation words to user)"
      ],
      "metadata": {
        "id": "BqAP3awqGyiA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bb7ac53"
      },
      "source": [
        "def course_summarize(course_description: str, llm, user_profile: dict = None) -> str:\n",
        "    \"\"\"\n",
        "    Generates a concise, user-friendly recommendation summary for a course using the LLM.\n",
        "    Can optionally condition on user_profile (e.g., career goals).\n",
        "    \"\"\"\n",
        "    if not course_description:\n",
        "        return \"No description available.\"\n",
        "\n",
        "    # Include user information in the prompt if available\n",
        "    if user_profile and \"career_goals\" in user_profile:\n",
        "        prompt = f\"\"\"Based on the user's future career goal of \"{user_profile['career_goals']}\", summarize the following course description into a single, appealing sentence recommendation that highlights its relevance to that goal:\n",
        "\n",
        "Course Description:\n",
        "{course_description}\n",
        "\n",
        "Recommendation:\n",
        "\"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"Summarize the following course description into a concise and appealing single-sentence recommendation that highlights the course's value:\n",
        "\n",
        "Course Description:\n",
        "{course_description}\n",
        "\n",
        "Recommendation:\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        messages = [smolagents.ChatMessage(role=\"user\", content=prompt)]\n",
        "        response = llm.generate(messages)\n",
        "        summary = response.content.strip()\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"Error during summarization: {e}\")\n",
        "        return \"Could not generate summary.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define audit_review_llm function(avoid bad response uploaded )"
      ],
      "metadata": {
        "id": "Anp1PpCpG6iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def audit_review_llm(text, llm):\n",
        "    prompt = f\"\"\"\n",
        "    Please perform an automatic AI audit of the given course review content based on the following rules:\n",
        "    1. If it contains rude, vulgar, or foul language (e.g., \"idiot\", \"go to hell\"), it fails the audit.\n",
        "    2. If the number of characters is less than 15, it fails the audit with the reason \"Content is too brief\".\n",
        "    3. Otherwise, it passes the audit, regardless of whether it expresses criticism or praise.\n",
        "    Return only: {{\"Audit Status\": \"Pass\"/\"Fail\", \"Reason\": \"...\"}}. Review text: {text}\n",
        "    \"\"\"\n",
        "    response = llm.generate([{\"role\":\"user\",\"content\": prompt}])\n",
        "    # Parse response.content as a dict\n",
        "    import json\n",
        "    try:\n",
        "        result = json.loads(response.content)\n",
        "    except Exception:\n",
        "        result = {\"Audit Status\": \"Fail\", \"Reason\": \"AI failed to correctly determine\"}\n",
        "    return result"
      ],
      "metadata": {
        "id": "KJKa_5Avd25m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get agent now( 3 tools!)"
      ],
      "metadata": {
        "id": "6pGDUkiRHKmO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82885b61"
      },
      "source": [
        "class CourseRecommenderAgent:\n",
        "    def __init__(self, courses, llm):\n",
        "        self.courses = courses\n",
        "        self.llm = llm\n",
        "\n",
        "    def course_match(self, user_profile):\n",
        "        return course_match(user_profile, self.courses)\n",
        "\n",
        "    def course_summarize(self, course_description, user_profile=None):\n",
        "        return course_summarize(course_description, self.llm, user_profile)\n",
        "\n",
        "    def course_review_audit(self, review_text):\n",
        "        return audit_review_llm(review_text, self.llm)\n",
        "\n",
        "    # Generic dispatch interface (optional)\n",
        "    def call(self, tool_name, **kwargs):\n",
        "        if tool_name == \"course_match\":\n",
        "            return self.course_match(kwargs[\"user_profile\"])\n",
        "        elif tool_name == \"course_summarize\":\n",
        "            return self.course_summarize(kwargs[\"course_description\"], kwargs.get(\"user_profile\"))\n",
        "        elif tool_name == \"course_review_audit\":\n",
        "            return self.course_review_audit(kwargs[\"review_text\"])\n",
        "        else:\n",
        "            raise ValueError(\"Unknown tool_name\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = CourseRecommenderAgent(cmu_courses, model_llama_real)\n"
      ],
      "metadata": {
        "id": "17S3Q2QYsdgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.llm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7TAUwEVxcM-",
        "outputId": "17815e3e-18a5-4e2b-ec5d-4f24e570846b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.LlamaCppModel object at 0x7d4388b779e0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try on gradio"
      ],
      "metadata": {
        "id": "MiAuZYHMHTCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import re\n",
        "\n",
        "# Assuming cmu_courses and agent are already initialized above, e.g.:\n",
        "# agent = CourseRecommenderAgent(cmu_courses, model_llama)\n",
        "\n",
        "course_choices = [f\"{c.get('course_id','Unknown')} {c.get('course_name','')}\" for c in cmu_courses]\n",
        "\n",
        "def recommend_block(resume, skills_str, career_goals):\n",
        "    try:\n",
        "        skills = [s.strip() for s in re.split('[,，；;、 ]', skills_str) if s.strip()]\n",
        "        user_profile = {\"resume\": resume, \"skills\": skills, \"career_goals\": career_goals}\n",
        "        expanded_profile = expand_profile(user_profile)\n",
        "        matches = agent.course_match(expanded_profile)\n",
        "        out = \"\"\n",
        "        for i, c in enumerate(matches[:15]):  # Display top 15 matches\n",
        "            # Combine output: Index + Course ID + Course Name + Match Percentage + Summarized Recommendation\n",
        "            out += (\n",
        "                f\"{i+1}. [{c['course_id']}] {c['course_name']} (Match: {c['matching_percentage']}%)\\n\"\n",
        "                f\"Recommendation: {agent.course_summarize(c['description'], user_profile)}\\n\\n\"\n",
        "            )\n",
        "        return out or \"No matching courses found.\"\n",
        "    except Exception:\n",
        "        import traceback; print(traceback.format_exc())\n",
        "        return \"An error occurred (please check input and look at Colab logs).\"\n",
        "\n",
        "def review_block(selected_course, workload, total_score, interest_score, useful_score, roi_score, review_text):\n",
        "    try:\n",
        "        review_struct = {\n",
        "            \"course_id\": (selected_course or 'Unknown').split()[0],\n",
        "            \"workload\": workload,\n",
        "            \"total_score\": total_score,\n",
        "            \"interest_score\": interest_score,\n",
        "            \"useful_score\": useful_score,\n",
        "            \"roi_score\": roi_score,\n",
        "            \"review_text\": review_text,\n",
        "        }\n",
        "        audit = agent.course_review_audit(review_text)\n",
        "        if audit.get(\"Audit Status\") == \"Pass\":\n",
        "            result = \"Review passed audit. Thank you for your submission!\"\n",
        "        else:\n",
        "            result = f\"Audit failed: {audit.get('Reason','No reason provided')}\"\n",
        "        return review_struct, result\n",
        "    except Exception:\n",
        "        import traceback; print(traceback.format_exc())\n",
        "        return {}, \"An error occurred (please check input and look at Colab logs).\"\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Course Recommendation & Review System Demo\")\n",
        "    with gr.Tab(\"Course Recommendation\"):\n",
        "        r_resume = gr.Textbox(label=\"Your Resume/Background (Required)\")\n",
        "        r_skills = gr.Textbox(label=\"Skills (Comma or space separated)\")\n",
        "        r_goal = gr.Textbox(label=\"Career Goal\")\n",
        "        r_output = gr.Textbox(label=\"Recommendation Results\", lines=15)\n",
        "        r_btn = gr.Button(\"Generate Recommendation\")\n",
        "        r_btn.click(fn=recommend_block, inputs=[r_resume, r_skills, r_goal], outputs=r_output)\n",
        "    with gr.Tab(\"Contribute Course Review\"):\n",
        "        v_course = gr.Dropdown(choices=course_choices, label=\"Course ID - Course Name\")\n",
        "        v_workload = gr.Textbox(label=\"Weekly Workload (Hours)\")\n",
        "        v_total = gr.Slider(1,5,step=1,label=\"Total Score\")\n",
        "        v_interest = gr.Slider(1,5,step=1,label=\"Interest Score\")\n",
        "        v_useful = gr.Slider(1,5,step=1,label=\"Usefulness Score\")\n",
        "        v_roi = gr.Slider(1,5,step=1,label=\"ROI Score\")\n",
        "        v_text = gr.Textbox(label=\"Freeform Review (Minimum 10 characters recommended)\")\n",
        "        v_out_struct = gr.JSON(label=\"Your Submitted Data\")\n",
        "        v_out_msg = gr.Textbox(label=\"Audit & Feedback\")\n",
        "        v_btn = gr.Button(\"Submit Review\")\n",
        "        v_btn.click(fn=review_block, inputs=[v_course, v_workload, v_total, v_interest, v_useful, v_roi, v_text],\n",
        "                    outputs=[v_out_struct, v_out_msg])\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "VOVObjxxr8Ur",
        "outputId": "93484aea-0df4-4726-d76e-b59e07f4a78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://f616790f632f7b7029.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f616790f632f7b7029.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7865 <> https://f616790f632f7b7029.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    }
  ]
}